server:
  port: 8080

openai:
  url: https://api.openai.com/v1/chat/completions
  key: ${SPRING_AI_OPENAI_API_KEY}
  model: gpt-4o
  config:
    max-tokens: 1512
    temperature: 1

spring:
  temporal:
    namespace: default
    connection:
      target: 127.0.0.1:7233
    # (Note following configuration are not set by default but serve more as reference)
    #    workers:
    #      - task-queue: DemoTaskQueue
    #        capacity:
    #          max-concurrent-workflow-task-pollers: 6
    #          max-concurrent-activity-task-pollers: 6
    #        rate-limits:
    #          max-worker-activities-per-second: 3
    #          max-task-queue-activities-per-second: 3
    #    workflow-cache:
    #      max-instances: 10
    #      max-threads: 10
    workersAutoDiscovery:
      packages: org.blueliner.springbootwithkotlin
  ai:
    openai:
      chat:
        api-key: ${SPRING_AI_OPENAI_API_KEY}
        options:
          temperature: 1
          model: gpt-4o-mini
    retry:
      max-attempts: 3
      backoff:
        initial-interval: 1500
        multiplier: 2
      on-client-errors: false # use retry even status is 4xx. Don't use it because of the request limit policy